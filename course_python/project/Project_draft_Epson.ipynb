{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "Use data collected from a Samsung health app to draw relevant conclusions.\n",
    "\n",
    "#### Files:\n",
    "+ [sleep-export2.csv](https://www.dropbox.com/s/7fdmc0l3410g8hu/sleep-export2.csv?dl=0)\n",
    "+ [exercise.csv](https://www.dropbox.com/s/swvtjxw2ilcn4pl/exercise.csv?dl=0)\n",
    "+ [heart_rate.csv](https://www.dropbox.com/s/7h2sphkvf4cjbsh/heart_rate.csv?dl=0)\n",
    "+ [Step_Count](https://www.dropbox.com/s/4edk6mwwsb6dogp/step_co7unt.csv?dl=0)\n",
    "+ [Floors_climbed](https://www.dropbox.com/s/wyde3yf57gurp1v/floors_climbed.csv?dl=0)\n",
    "\n",
    "#### Jupyter Notebook:\n",
    "+ Set up\n",
    "  + Imports\n",
    "  + Define Retrieve_Data class\n",
    "+ Preprocess each data file individually\n",
    "  + Convert time labels to meaningful format\n",
    "  + Create coarse features, such as\n",
    "    + Sleep hour\n",
    "    + Day of the week\n",
    "    + Time since timezone has changed\n",
    "+ Merge data from the multiple sources\n",
    "+ Analyze individual files\n",
    "+ Analyze the combined data\n",
    "\n",
    "#### Classes:\n",
    "+ Retrieve_Time\n",
    "+ Merge_Data\n",
    "\n",
    "#### Samsung app documentation:\n",
    "+ [Technical details](https://developer.samsung.com/html/techdoc/ProgrammingGuide_SHealthService.pdf)\n",
    "+ [Property description](https://developer.samsung.com/onlinedocs/health/index.html?com/samsung/android/sdk/healthdata/HealthConstants.Sleep.html)\n",
    "+ [Health data](https://developer.samsung.com/onlinedocs/health/index.html?com/samsung/android/sdk/healthdata/HealthConstants.html)\n",
    "\n",
    "#### Notes:\n",
    "+ The reported times are all measured at the UTC timezone. They are corrected for the local time for these analyses. (See Field Detail - START_TIME in the app [documentation](https://developer.samsung.com/onlinedocs/health/index.html?com/samsung/android/sdk/healthdata/HealthConstants.Sleep.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Set up\n",
    "+ Imports\n",
    "+ Define Retrieve_Data class\n",
    "+ Define Merge_Data class\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from dateutil import tz\n",
    "from collections import Counter\n",
    "%matplotlib inline\n",
    "\n",
    "#Set matplotlib variables for prettier plots.\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams['font.family'] = 'STIXGeneral'\n",
    "fs = 36."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rerieve_Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retrieve_Timestamps(object):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "    Given a list of time strings, convert it to a datetime object which is in the\n",
    "    local timezone.\n",
    "    \"\"\"        \n",
    "    def __init__(self, target, tz_true, tz_used, inp_format, time_format):\n",
    "        self.target = target\n",
    "        self.tz_true = tz_true\n",
    "        self.tz_used = tz_used\n",
    "        self.inp_format = inp_format\n",
    "        self.time_format = time_format\n",
    "        \n",
    "        self.out = None\n",
    "        self.time_obj = None\n",
    "                \n",
    "        self.create_date_obj()\n",
    "        self.get_corrected_timeobj()\n",
    "\n",
    "    def create_date_obj(self):\n",
    "        if self.inp_format == 'datestr':\n",
    "            self.time_obj = np.array(\n",
    "              [datetime.strptime(t, self.time_format) for t in self.target])\n",
    "        elif self.inp_format == 'milisec':\n",
    "            self.time_obj = np.array(\n",
    "              [datetime.fromtimestamp(t) for t in self.target])            \n",
    "        else:\n",
    "            raise ValueError('inp_format of %s is not accepeted.'\\\n",
    "                             %(self.inp_format))\n",
    "\n",
    "    def get_corrected_timeobj(self):\n",
    "        from_zone = tz.gettz(self.tz_used)\n",
    "        to_zone = [tz.gettz(t_off) for t_off in self.tz_true]\n",
    "        \n",
    "        #The timezone information below is erased for compatibility with pandas resample.\n",
    "        self.out = np.array([_t.replace(tzinfo=from_zone).astimezone(_to_zone).replace(tzinfo=None)\n",
    "                            for (_t,_to_zone) in zip(self.time_obj,to_zone)])\n",
    "\n",
    "#Run tests\n",
    "def run_tests():\n",
    "    assert\\\n",
    "        Retrieve_Timestamps(['2018-04-07 17:26:10'], 'UTC', 'UTC-0200', 'datestr', '%Y-%m-%d %H:%M:%S').out\\\n",
    "        == [datetime(2018, 4, 7, 15, 26, 10)], ValueError('Time conversion not working.')\n",
    "    assert\\\n",
    "        Retrieve_Timestamps([1326244364], 'UTC', 'UTC-0200', 'milisec', '%Y-%m-%d %H:%M:%S').out\\\n",
    "        == [datetime(2012, 1, 10, 17, 12, 44)], ValueError('Time conversion not working.')\n",
    "    \n",
    "run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Analysis: sleep data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = './data/sleep-export2.csv'\n",
    "sleep_df = pd.read_csv(fpath, header=0, index_col=0, low_memory=False)\n",
    "\n",
    "#Rename columns for simplicity.\n",
    "newcols = {col : col.replace('com.samsung.health.sleep.', '') for col in sleep_df.columns}\n",
    "sleep_df.rename(columns=newcols, inplace=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date:  2017-12-15 20:02:00\n",
      "End date:  2018-07-28 21:04:00\n"
     ]
    }
   ],
   "source": [
    "#Use the Retrieve_Timestamps class to convert timestamps to readable values.\n",
    "time_format = '%Y-%m-%d %H:%M:%S.%f'\n",
    "starttime_obj = Retrieve_Timestamps(\n",
    "  sleep_df['start_time'].values/1000., sleep_df['time_offset'].values, 'UTC', 'milisec', time_format).out\n",
    "endtime_obj = Retrieve_Timestamps(\n",
    "  sleep_df['end_time'].values/1000., sleep_df['time_offset'].values, 'UTC', 'milisec', time_format).out\n",
    "sleep_df['Start_time_obj'] = starttime_obj\n",
    "\n",
    "#Compute hour of the day the measurement started.\n",
    "sleep_df['start_hour'] = np.array([t.hour + t.minute/60. + t.second/3600. for t in starttime_obj])\n",
    "\n",
    "#Compute day of the week.\n",
    "sleep_df['weekday'] = np.array([calendar.day_name[t.weekday()] for t in starttime_obj])\n",
    "\n",
    "#Compute sleep duration.\n",
    "duration = endtime_obj - starttime_obj\n",
    "sleep_df['sleep_duration'] = np.array([t.days*24.*60 + t.seconds/60. for t in duration]) #In minutes\n",
    "\n",
    "#Compute time progression.\n",
    "ref_date = min(starttime_obj)\n",
    "time_prog = starttime_obj - ref_date\n",
    "sleep_df['time_prog'] = np.array([t.days + t.seconds/86400. for t in time_prog]) #In days\n",
    "\n",
    "#Sort sleep data according to time progression.\n",
    "sleep_df.sort_values(by ='time_prog', inplace=True)\n",
    "\n",
    "print('Start date: ', (min(starttime_obj)))\n",
    "print('End date: ', (max(starttime_obj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute time elapsed since a timezone change.\n",
    "#Compute number of days since time zone change.\n",
    "time_since = 0.\n",
    "tz_duration = []\n",
    "for ((index2,row2),(index1,row1)) in zip(sleep_df.shift(1).iterrows(),sleep_df.iterrows()):\n",
    "    if row1['time_offset'] == row2['time_offset']:\n",
    "        time_since += (row1['time_prog'] - row2['time_prog']) #Additional time transpired since the tz changed.\n",
    "    else:\n",
    "        time_since = 0.\n",
    "    tz_duration.append(time_since)\n",
    "\n",
    "tz_duration = np.array(tz_duration)    \n",
    "\n",
    "#We do not need tz_duration to be fine for plotting purposes.\n",
    "def coarsify_duration(x):\n",
    "    if x <= 2.:\n",
    "        return 'tz < 2'\n",
    "    elif (x > 2.) and (x <= 5.):\n",
    "        return '2 < tz < 5'\n",
    "    elif (x > 5.):\n",
    "        return 'tz > 5'\n",
    "\n",
    "sleep_df['tz_duration'] = [coarsify_duration(tz) for tz in tz_duration]\n",
    "#We don't know for how long the person had been on the initial time zone.\n",
    "sleep_df['tz_duration'].iloc[0:3] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate the data according to date.\n",
    "aggregator = {'sleep_duration':'sum', 'efficiency':'mean', 'tz_duration':'first'}\n",
    "sleep_agg_df = sleep_df.resample('D', on='Start_time_obj').agg(aggregator)\n",
    "sleep_agg_df = sleep_agg_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Analysis: Exercise\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = './data/exercise.csv'\n",
    "exer_df = pd.read_csv(fpath, header=0, index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = './data/step_count.csv'\n",
    "step_df = pd.read_csv(fpath, header=0, index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Analysis: Heart rate\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = './data/heart_rate.csv'\n",
    "heart_df = pd.read_csv(fpath, header=0, index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date:  2016-06-11 13:08:27.445000\n",
      "End date:  2018-04-25 14:46:13.476000\n"
     ]
    }
   ],
   "source": [
    "time_format = '%Y-%m-%d %H:%M:%S.%f'\n",
    "#Use the Retrieve_Timestamps class to convert timestamps to readable values.\n",
    "starttime_obj = Retrieve_Timestamps(\n",
    "  heart_df['start_time'].values, heart_df['time_offset'].values, 'UTC', 'datestr', time_format).out\n",
    "#The two earliest dates seem spurious. Remove them.\n",
    "heart_df = heart_df.drop(heart_df[heart_df.start_time == min(heart_df.start_time)].index)\n",
    "\n",
    "#Re-calculate datetime objects without the spurious entries.\n",
    "starttime_obj = Retrieve_Timestamps(\n",
    "  heart_df['start_time'].values, heart_df['time_offset'].values, 'UTC', 'datestr', time_format).out\n",
    "endtime_obj = Retrieve_Timestamps(\n",
    "  heart_df['end_time'].values, heart_df['time_offset'].values, 'UTC', 'datestr', time_format).out\n",
    "\n",
    "#Compute hour of the day the measurement started.\n",
    "heart_df['start_hour'] = np.array([t.hour + t.minute/60. + t.second/3600. for t in starttime_obj])\n",
    "\n",
    "#Compute day of the week.\n",
    "heart_df['weekday'] = np.array([calendar.day_name[t.weekday()] for t in starttime_obj])\n",
    "\n",
    "#Compute time progression.\n",
    "ref_date = min(starttime_obj)\n",
    "time_prog = starttime_obj - ref_date\n",
    "heart_df['time_prog'] = np.array([t.days + t.seconds/86400. for t in time_prog]) #In days\n",
    "\n",
    "#Sort sleep data according to time progression.\n",
    "heart_df.sort_values(by ='time_prog', inplace=True)\n",
    "\n",
    "print('Start date: ', (min(starttime_obj)))\n",
    "print('End date: ', (max(starttime_obj)))\n",
    "\n",
    "#Note: The duration seems to be a fixed small interval, which\n",
    "#indicates that the heart_rate entry is the instantaneous heart_rate\n",
    "#at the start time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Analysis: Floors climbed\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = './data/floors_climbed.csv'\n",
    "floor_df = pd.read_csv(fpath, header=0, index_col=0, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start date:  2017-12-16 04:46:12\n",
      "End date:  2018-05-03 05:13:11\n"
     ]
    }
   ],
   "source": [
    "#Use the Retrieve_Timestamps class to convert timestamps to readable values.\n",
    "starttime_obj = Retrieve_Timestamps(\n",
    "  floor_df['start_time'].values, floor_df['time_offset'].values, 'UTC', 'datestr', time_format).out\n",
    "endtime_obj = Retrieve_Timestamps(\n",
    "  floor_df['end_time'].values, floor_df['time_offset'].values, 'UTC', 'datestr', time_format).out\n",
    "floor_df['Start_time_obj'] = starttime_obj\n",
    "\n",
    "#Compute hour of the day the measurement started.\n",
    "floor_df['start_hour'] = np.array([t.hour + t.minute/60. + t.second/3600. for t in starttime_obj])\n",
    "\n",
    "#Compute day of the week.\n",
    "floor_df['weekday'] = np.array([calendar.day_name[t.weekday()] for t in starttime_obj])\n",
    "\n",
    "#Compute duration. This is, supposedly always 1min.\n",
    "duration = endtime_obj - starttime_obj\n",
    "floor_df['floors_duration'] = np.array([t.days*24.*60 + t.seconds/60. for t in duration]) #In minutes\n",
    "\n",
    "#Compute time progression.\n",
    "ref_date = min(starttime_obj)\n",
    "time_prog = starttime_obj - ref_date\n",
    "floor_df['time_prog'] = np.array([t.days + t.seconds/86400. for t in time_prog]) #In days\n",
    "\n",
    "#Sort floors data according to time progression.\n",
    "floor_df.sort_values(by ='time_prog', inplace=True)\n",
    "\n",
    "print('Start date: ', (min(starttime_obj)))\n",
    "print('End date: ', (max(starttime_obj)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate the data according to date.\n",
    "aggregator = {'floor':'sum', 'floors_duration':'sum', }\n",
    "floor_agg_df = floor_df.resample('D', on='Start_time_obj').agg(aggregator)\n",
    "floor_agg_df = floor_agg_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Merge data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.merge(sleep_agg_df, floor_agg_df, how='left', on='Start_time_obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Start_time_obj  sleep_duration  efficiency tz_duration  floor  \\\n",
      "0       2017-12-15           411.0   94.902916         NaN    NaN   \n",
      "1       2017-12-16             0.0         NaN         NaN   10.0   \n",
      "2       2017-12-17           491.0   96.341460         NaN    9.0   \n",
      "3       2017-12-18             0.0         NaN         NaN   13.0   \n",
      "4       2017-12-19           293.0   93.174065         NaN   10.0   \n",
      "..             ...             ...         ...         ...    ...   \n",
      "221     2018-07-24           374.0   92.266670      tz > 5    NaN   \n",
      "222     2018-07-25           499.0   89.779564      tz > 5    NaN   \n",
      "223     2018-07-26           459.0   92.826090      tz > 5    NaN   \n",
      "224     2018-07-27           521.0   90.804596      tz > 5    NaN   \n",
      "225     2018-07-28           425.0   89.906105      tz > 5    NaN   \n",
      "\n",
      "     floors_duration    weekday  time_prog  \n",
      "0                NaN     Friday          0  \n",
      "1           2.266667   Saturday          1  \n",
      "2           2.166667     Sunday          2  \n",
      "3           7.633333     Monday          3  \n",
      "4           2.016667    Tuesday          4  \n",
      "..               ...        ...        ...  \n",
      "221              NaN    Tuesday        221  \n",
      "222              NaN  Wednesday        222  \n",
      "223              NaN   Thursday        223  \n",
      "224              NaN     Friday        224  \n",
      "225              NaN   Saturday        225  \n",
      "\n",
      "[226 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "#Derive quantities for merged data. This avoids confusion in trying\n",
    "#to merge these quantities from the original data sets.\n",
    "time_obj = pd.to_datetime(master_df['Start_time_obj'].values)\n",
    "\n",
    "#Compute day of the week.\n",
    "master_df['weekday'] = np.array([calendar.day_name[t.weekday()] for t in time_obj])\n",
    "\n",
    "#Compute time progression.\n",
    "ref_date = min(time_obj)\n",
    "time_prog = time_obj - ref_date\n",
    "master_df['time_prog'] = np.array([t.days for t in time_prog]) #In days, same as the index.\n",
    "print(master_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Analysis: Combined data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
